{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c83857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa5978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_names = ['Final', 'Third-place', 'Semi-finals-1', 'Semi-finals-2', 'Quarter-final-1', 'Quarter-final-2', \n",
    "               'Quarter-final-3', 'Quarter-final-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45660493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(match, url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    table = soup.find_all('div', class_ = 'table_wrapper')\n",
    "    keys = [i.select('caption')[0].text for i in table[:4]]\n",
    "\n",
    "    for i in range(4):\n",
    "        match[keys[i]] = pd.read_html(str(table[i]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0005cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(event, event_stats, url):\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    matches = soup.find_all('div', class_ = 'match-summary')\n",
    "\n",
    "    for i in range(len(match_names)):\n",
    "\n",
    "        match = match_names[i]\n",
    "        event[match]={}\n",
    "        event_stats[match]={}\n",
    "\n",
    "        event[match]['winner'] = matches[i].select('a')[0].text\n",
    "        event[match]['loser'] = matches[i].select('a')[2].text\n",
    "        event[match]['winner_goal'] = matches[i].select('a')[1].text.split('–')[0]\n",
    "        event[match]['loser_goal'] = matches[i].select('a')[1].text.split('–')[0]\n",
    "        url_match = 'https://fbref.com' + matches[i].select('a')[1].get('href')\n",
    "\n",
    "        get_names(event_stats[match], url_match)\n",
    "        time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e9ce6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WC_2007 = {}\n",
    "WC_2007_stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f7d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_match(WC_2007, WC_2007_stats, 'https://fbref.com/en/comps/106/2007/2007-Womens-World-Cup-Stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b2b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in match_names:\n",
    "    os.mkdir('WC_2007/'+key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47858be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in WC_2007.keys():\n",
    "    df = pd.DataFrame.from_dict(WC_2007[key],orient='index')\n",
    "    df.to_csv('WC_2007/'+key+'/result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80296fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in WC_2007.keys():\n",
    "    for tag in WC_2007_stats[key].keys():\n",
    "        df = WC_2007_stats[key][tag]\n",
    "        df.to_csv('WC_2007/'+key+'/'+tag+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945924bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
